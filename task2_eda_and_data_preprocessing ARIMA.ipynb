{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/RMCV-Rajapaksha/TeamInception_Datathon/blob/main/task2_eda_and_data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEFxJ2Xen2oD"
   },
   "source": [
    "# Task 1 Notebook for \"insert model name here\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MEUTVXun8N0"
   },
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0ecqx8Tn_Dp"
   },
   "source": [
    "**Import the Libararies**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ApAumUHPn76R"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0SilpfYoykJ"
   },
   "source": [
    "### Reading data set files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJRP655yoPHn"
   },
   "outputs": [],
   "source": [
    "# Developers please update the paths according to were in your google you place datasets\n",
    "# i recommend making Rootcode-ML folder and in it Datasets folder and placing the csv files there then you wont have to change below code block\n",
    "bookings_data = pd.read_csv('./dataset/bookings_train.csv')\n",
    "tasks_data = pd.read_csv('./dataset/tasks.csv')\n",
    "staffing_data = pd.read_csv('./dataset/staffing_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcPsAJ5HphnZ"
   },
   "source": [
    "## EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCw9gAX2pmPi"
   },
   "source": [
    "### EDA of Bookings data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37sGEybgpprQ"
   },
   "source": [
    "lets take a look at the columns and some of their values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "8cEYNLzxpkBU",
    "outputId": "9a30db86-6314-44e1-bfea-8189c7b2d5c7"
   },
   "outputs": [],
   "source": [
    "staffing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "aCI5njmSpzhq",
    "outputId": "e1ca61a6-8d5a-48bf-f95d-3796c53f2f1b"
   },
   "outputs": [],
   "source": [
    "staffing_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zR4skDiPp52m"
   },
   "source": [
    "removing unnecessary columns. We wont need the total_task_time_minutes because this data wont be provided as input from the test datasets. We need the date and section_id  because they will be to calculate the actual target value (the thing to be predicted) for task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZevs-sMqZHH"
   },
   "outputs": [],
   "source": [
    "staffing_data = staffing_data.drop(['total_task_time_minutes'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7f-tHmNJqmmi"
   },
   "source": [
    "now lets look at the new table headers again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "a4F4lAvNqnb_",
    "outputId": "6101ffa2-5789-4c25-97e4-91edaf844321"
   },
   "outputs": [],
   "source": [
    "staffing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0J-Q8Smqu5U"
   },
   "source": [
    "lets get a better idea of how null values have been distributed amoung the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "DWHVTtkqqvU6",
    "outputId": "69b2cb22-ad1a-4914-c6b8-f6f0c2fe5fd9"
   },
   "outputs": [],
   "source": [
    "staffing_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1qOKU_bsiY_"
   },
   "source": [
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SDM55q5snxx"
   },
   "source": [
    "### Rearrangement and processing of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sruAk95sqT8"
   },
   "source": [
    "### Dataset seperation according to section_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "lI9aeRhnslpG",
    "outputId": "dfc6ae45-bb06-421a-ca4f-ebd54473b2a8"
   },
   "outputs": [],
   "source": [
    "task_counts = staffing_data.groupby(\"section_id\").size().reset_index(name=\"count\")\n",
    "task_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "il4CvOg5tKZT"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9mv-Rd9ptOhm"
   },
   "outputs": [],
   "source": [
    "sec_1_data = staffing_data[staffing_data['section_id'] == 'SEC-001'].copy()\n",
    "sec_2_data = staffing_data[staffing_data['section_id'] == 'SEC-002'].copy()\n",
    "sec_3_data = staffing_data[staffing_data['section_id'] == 'SEC-003'].copy()\n",
    "sec_4_data = staffing_data[staffing_data['section_id'] == 'SEC-004'].copy()\n",
    "sec_5_data = staffing_data[staffing_data['section_id'] == 'SEC-005'].copy()\n",
    "sec_6_data = staffing_data[staffing_data['section_id'] == 'SEC-006'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ElOj3joxw-Jw",
    "outputId": "43035933-13ca-4898-f370-deb33986f8e8"
   },
   "outputs": [],
   "source": [
    "sec_6_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date column to datetime for all section datasets\n",
    "for section_data in [sec_1_data, sec_2_data, sec_3_data, sec_4_data, sec_5_data, sec_6_data]:\n",
    "    section_data['date'] = pd.to_datetime(section_data['date'])\n",
    "    section_data.set_index('date', inplace=True)\n",
    "    section_data.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(data, column):\n",
    "    \"\"\"Remove outliers using IQR method\"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Create a copy without outliers\n",
    "    data_clean = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)].copy()\n",
    "    \n",
    "    print(f\"Original data points: {len(data)}\")\n",
    "    print(f\"Data points after outlier removal: {len(data_clean)}\")\n",
    "    print(f\"Outliers removed: {len(data) - len(data_clean)}\")\n",
    "    \n",
    "    return data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_time_series(data, train_ratio=0.7, val_ratio=0.15):\n",
    "    \"\"\"Split time series data into train, validation, and test sets\"\"\"\n",
    "    n = len(data)\n",
    "    train_size = int(n * train_ratio)\n",
    "    val_size = int(n * val_ratio)\n",
    "    \n",
    "    train_data = data.iloc[:train_size]\n",
    "    val_data = data.iloc[train_size:train_size + val_size]\n",
    "    test_data = data.iloc[train_size + val_size:]\n",
    "    \n",
    "    print(f\"Train set: {len(train_data)} samples\")\n",
    "    print(f\"Validation set: {len(val_data)} samples\") \n",
    "    print(f\"Test set: {len(test_data)} samples\")\n",
    "    \n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_arima(train_data, max_p=3, max_d=2, max_q=3):\n",
    "    \"\"\"Find best ARIMA parameters using AIC\"\"\"\n",
    "    best_aic = float('inf')\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    for p in range(max_p + 1):\n",
    "        for d in range(max_d + 1):\n",
    "            for q in range(max_q + 1):\n",
    "                try:\n",
    "                    model = ARIMA(train_data['employees_on_duty'], order=(p, d, q))\n",
    "                    fitted_model = model.fit()\n",
    "                    aic = fitted_model.aic\n",
    "                    \n",
    "                    if aic < best_aic:\n",
    "                        best_aic = aic\n",
    "                        best_params = (p, d, q)\n",
    "                        best_model = fitted_model\n",
    "                        \n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    print(f\"Best ARIMA parameters: {best_params}\")\n",
    "    print(f\"Best AIC: {best_aic:.2f}\")\n",
    "    \n",
    "    return best_model, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"PROCESSING SECTION 1 (SEC-001)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Remove outliers from training data only\n",
    "# sec_1_clean = remove_outliers_iqr(sec_1_data, 'employees_on_duty')\n",
    "\n",
    "# Split the cleaned data\n",
    "train_1, val_1, test_1 = split_time_series(sec_1_data)\n",
    "\n",
    "# Find best ARIMA model\n",
    "best_model_1, best_params_1 = find_best_arima(train_1)\n",
    "\n",
    "print(\"\\nSection 1 Model Summary:\")\n",
    "print(best_model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"PROCESSING SECTION 2 (SEC-002)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Remove outliers from training data only\n",
    "# sec_2_clean = remove_outliers_iqr(sec_2_data, 'employees_on_duty')\n",
    "\n",
    "# Split the cleaned data\n",
    "train_2, val_2, test_2 = split_time_series(sec_2_data)\n",
    "\n",
    "# Find best ARIMA model\n",
    "best_model_2, best_params_2 = find_best_arima(train_2)\n",
    "\n",
    "print(\"\\nSection 2 Model Summary:\")\n",
    "print(best_model_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"PROCESSING SECTION 3 (SEC-003)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Remove outliers from training data only\n",
    "# sec_3_clean = remove_outliers_iqr(sec_3_data, 'employees_on_duty')\n",
    "\n",
    "# Split the cleaned data\n",
    "train_3, val_3, test_3 = split_time_series(sec_3_data)\n",
    "\n",
    "# Find best ARIMA model\n",
    "best_model_3, best_params_3 = find_best_arima(train_3)\n",
    "\n",
    "print(\"\\nSection 3 Model Summary:\")\n",
    "print(best_model_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"PROCESSING SECTION 4 (SEC-004)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Remove outliers from training data only\n",
    "# sec_4_clean = remove_outliers_iqr(sec_4_data, 'employees_on_duty')\n",
    "\n",
    "# Split the cleaned data\n",
    "train_4, val_4, test_4 = split_time_series(sec_4_data)\n",
    "\n",
    "# Find best ARIMA model\n",
    "best_model_4, best_params_4 = find_best_arima(train_4)\n",
    "\n",
    "print(\"\\nSection 4 Model Summary:\")\n",
    "print(best_model_4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"PROCESSING SECTION 5 (SEC-005)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Remove outliers from training data only\n",
    "# sec_5_clean = remove_outliers_iqr(sec_5_data, 'employees_on_duty')\n",
    "\n",
    "# Split the cleaned data\n",
    "train_5, val_5, test_5 = split_time_series(sec_5_data)\n",
    "\n",
    "# Find best ARIMA model\n",
    "best_model_5, best_params_5 = find_best_arima(train_5)\n",
    "\n",
    "print(\"\\nSection 5 Model Summary:\")\n",
    "print(best_model_5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"PROCESSING SECTION 6 (SEC-006)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Remove outliers from training data only\n",
    "# sec_6_clean = remove_outliers_iqr(sec_6_data, 'employees_on_duty')\n",
    "\n",
    "# Split the cleaned data\n",
    "train_6, val_6, test_6 = split_time_series(sec_6_data)\n",
    "\n",
    "# Find best ARIMA model\n",
    "best_model_6, best_params_6 = find_best_arima(train_6)\n",
    "\n",
    "print(\"\\nSection 6 Model Summary:\")\n",
    "print(best_model_6.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, train_data, val_data, test_data):\n",
    "    \"\"\"Make predictions on validation and test sets\"\"\"\n",
    "    \n",
    "    # Predict on validation set\n",
    "    val_start = len(train_data)\n",
    "    val_end = val_start + len(val_data) - 1\n",
    "    val_pred = model.predict(start=val_start, end=val_end)\n",
    "    \n",
    "    # Predict on test set\n",
    "    test_start = len(train_data) + len(val_data)\n",
    "    test_end = test_start + len(test_data) - 1\n",
    "    test_pred = model.predict(start=test_start, end=test_end)\n",
    "    \n",
    "    return val_pred, test_pred\n",
    "\n",
    "def calculate_metrics(actual, predicted):\n",
    "    \"\"\"Calculate evaluation metrics\"\"\"\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "    mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "    accuracy = r2_score(actual, predicted)\n",
    "\n",
    "    return mae, rmse, mape, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all models and data for plotting\n",
    "models = [best_model_1, best_model_2, best_model_3, best_model_4, best_model_5, best_model_6]\n",
    "train_sets = [train_1, train_2, train_3, train_4, train_5, train_6]\n",
    "val_sets = [val_1, val_2, val_3, val_4, val_5, val_6]\n",
    "test_sets = [test_1, test_2, test_3, test_4, test_5, test_6]\n",
    "section_names = ['SEC-001', 'SEC-002', 'SEC-003', 'SEC-004', 'SEC-005', 'SEC-006']\n",
    "\n",
    "# Generate predictions for all sections\n",
    "all_predictions = {}\n",
    "all_metrics = {}\n",
    "\n",
    "for i, section in enumerate(section_names):\n",
    "    print(f\"\\nGenerating predictions for {section}...\")\n",
    "    \n",
    "    val_pred, test_pred = make_predictions(models[i], train_sets[i], val_sets[i], test_sets[i])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    val_mae, val_rmse, val_mape, val_acc = calculate_metrics(val_sets[i]['employees_on_duty'], val_pred)\n",
    "    test_mae, test_rmse, test_mape, test_acc = calculate_metrics(test_sets[i]['employees_on_duty'], test_pred)\n",
    "    \n",
    "    all_predictions[section] = {\n",
    "        'val_pred': val_pred,\n",
    "        'test_pred': test_pred\n",
    "    }\n",
    "    \n",
    "    all_metrics[section] = {\n",
    "        'val_metrics': {'MAE': val_mae, 'RMSE': val_rmse, 'MAPE': val_mape, 'ACC': val_acc},\n",
    "        'test_metrics': {'MAE': test_mae, 'RMSE': test_rmse, 'MAPE': test_mape, 'ACC': test_acc}\n",
    "    }\n",
    "    \n",
    "    print(f\"Validation - MAE: {val_mae:.2f}, RMSE: {val_rmse:.2f}, MAPE: {val_mape:.2f}%, ACC: {val_acc:.2f}\")\n",
    "    print(f\"Test - MAE: {test_mae:.2f}, RMSE: {test_rmse:.2f}, MAPE: {test_mape:.2f}%, ACC: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(section_idx, section_name):\n",
    "    \"\"\"Plot actual vs predicted values for a section\"\"\"\n",
    "    \n",
    "    train_data = train_sets[section_idx]\n",
    "    val_data = val_sets[section_idx]\n",
    "    test_data = test_sets[section_idx]\n",
    "    val_pred = all_predictions[section_name]['val_pred']\n",
    "    test_pred = all_predictions[section_name]['test_pred']\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Plot actual data\n",
    "    plt.plot(train_data.index, train_data['employees_on_duty'], \n",
    "             label='Training Data', color='blue', alpha=0.7)\n",
    "    plt.plot(val_data.index, val_data['employees_on_duty'], \n",
    "             label='Validation Actual', color='green', alpha=0.7)\n",
    "    plt.plot(test_data.index, test_data['employees_on_duty'], \n",
    "             label='Test Actual', color='red', alpha=0.7)\n",
    "    \n",
    "    # Plot predictions\n",
    "    plt.plot(val_data.index, val_pred, \n",
    "             label='Validation Predicted', color='lightgreen', linestyle='--', linewidth=2)\n",
    "    plt.plot(test_data.index, test_pred, \n",
    "             label='Test Predicted', color='orange', linestyle='--', linewidth=2)\n",
    "    \n",
    "    plt.title(f'{section_name} - Actual vs Predicted Employees', fontsize=16)\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Number of Employees', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add metrics text\n",
    "    val_metrics = all_metrics[section_name]['val_metrics']\n",
    "    test_metrics = all_metrics[section_name]['test_metrics']\n",
    "    \n",
    "    metrics_text = f\"Validation: MAE={val_metrics['MAE']:.2f}, RMSE={val_metrics['RMSE']:.2f}, MAPE={val_metrics['MAPE']:.1f}%\\n\"\n",
    "    metrics_text += f\"Test: MAE={test_metrics['MAE']:.2f}, RMSE={test_metrics['RMSE']:.2f}, MAPE={test_metrics['MAPE']:.1f}%\"\n",
    "    \n",
    "    plt.text(0.02, 0.98, metrics_text, transform=plt.gca().transAxes, \n",
    "             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results for Section 1\n",
    "plot_predictions(0, 'SEC-001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results for Section 2\n",
    "plot_predictions(1, 'SEC-002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results for Section 3\n",
    "plot_predictions(2, 'SEC-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results for Section 4\n",
    "plot_predictions(3, 'SEC-004')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results for Section 5\n",
    "plot_predictions(4, 'SEC-005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results for Section 6\n",
    "plot_predictions(5, 'SEC-006')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive comparison plot\n",
    "fig, axes = plt.subplots(3, 2, figsize=(20, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, section in enumerate(section_names):\n",
    "    train_data = train_sets[i]\n",
    "    val_data = val_sets[i]\n",
    "    test_data = test_sets[i]\n",
    "    val_pred = all_predictions[section]['val_pred']\n",
    "    test_pred = all_predictions[section]['test_pred']\n",
    "    \n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot actual data\n",
    "    ax.plot(train_data.index, train_data['employees_on_duty'], \n",
    "            label='Training', color='blue', alpha=0.6, linewidth=1)\n",
    "    ax.plot(val_data.index, val_data['employees_on_duty'], \n",
    "            label='Val Actual', color='green', alpha=0.8, linewidth=1.5)\n",
    "    ax.plot(test_data.index, test_data['employees_on_duty'], \n",
    "            label='Test Actual', color='red', alpha=0.8, linewidth=1.5)\n",
    "    \n",
    "    # Plot predictions\n",
    "    ax.plot(val_data.index, val_pred, \n",
    "            label='Val Pred', color='lightgreen', linestyle='--', linewidth=2)\n",
    "    ax.plot(test_data.index, test_pred, \n",
    "            label='Test Pred', color='orange', linestyle='--', linewidth=2)\n",
    "    \n",
    "    ax.set_title(f'{section}', fontsize=14)\n",
    "    ax.set_xlabel('Date', fontsize=10)\n",
    "    ax.set_ylabel('Employees', fontsize=10)\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Rotate x-axis labels\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('ARIMA Predictions for All Sections - Actual vs Predicted', fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance summary\n",
    "print(\"=\" * 80)\n",
    "print(\"PERFORMANCE SUMMARY - ALL SECTIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "\n",
    "for section in section_names:\n",
    "    val_metrics = all_metrics[section]['val_metrics']\n",
    "    test_metrics = all_metrics[section]['test_metrics']\n",
    "    \n",
    "    row_data = {\n",
    "        'Section': section,\n",
    "        'Val_MAE': val_metrics['MAE'],\n",
    "        'Val_RMSE': val_metrics['RMSE'], \n",
    "        'Val_MAPE': val_metrics['MAPE'],\n",
    "        'Val_ACC': val_metrics['ACC'],\n",
    "        'Test_MAE': test_metrics['MAE'],\n",
    "        'Test_RMSE': test_metrics['RMSE'],\n",
    "        'Test_MAPE': test_metrics['MAPE'],\n",
    "        'Test_ACC': test_metrics['ACC']\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.concat([summary_df, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Display the summary table\n",
    "print(summary_df.round(2).to_string(index=False))\n",
    "\n",
    "# Calculate average performance\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"AVERAGE PERFORMANCE ACROSS ALL SECTIONS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Average Validation MAE: {summary_df['Val_MAE'].mean():.2f}\")\n",
    "print(f\"Average Validation RMSE: {summary_df['Val_RMSE'].mean():.2f}\")\n",
    "print(f\"Average Validation MAPE: {summary_df['Val_MAPE'].mean():.2f}%\")\n",
    "print(f\"Average Test MAE: {summary_df['Test_MAE'].mean():.2f}\")\n",
    "print(f\"Average Test RMSE: {summary_df['Test_RMSE'].mean():.2f}\")\n",
    "print(f\"Average Test MAPE: {summary_df['Test_MAPE'].mean():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPqB3VkIXgpEuMZsaj6lRUH",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "teaminception-datathon (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
